#+TITLE: Software Usage Collection and Analysis with ELK at CAEN
#+AUTHOR: Andrew Caird
#+EMAIL: acaird@umich.edu
#+OPTIONS: ':t H:3 \n:nil ^:{} author:t toc:nil
#+CREATOR: Emacs 24.3.1 (Org mode 8.2.7b)
#+DESCRIPTION:
#+EXCLUDE_TAGS: noexport
#+KEYWORDS:
#+LANGUAGE: en
#+SELECT_TAGS: export

#+BEGIN_HTML
---
layout: page
title: Software Usage Collection and Analysis with ELK at CAEN
---
#+END_HTML

# http://stackoverflow.com/questions/24909918/org-mode-macros-inside-code-blocks-and-using-babel
# https://github.com/dakrone/es-mode

CAEN supports 100s of software packages in its student computing labs
and in its HPC environment, and the list grows every year.  To help us
make decisions about software usage patterns, we wanted to collect and
analyze data on a per-title, per-computer, per-user basis.

By gathering software usage information for everything that CAEN
installs, we hope to:
 - get a better understanding of what software is used, so we can
   remove titles that we donâ€™t need to be installing
 - correlate titles with courses, and try to suggest that similar
   courses use the same software to minimize what the students have to
   learn, the instructors have to teach, and CAEN has to support
 - make purchasing and labor decisions based on more than just an
   educated guess

* ELK
  The open-source [[http://www.elasticsearch.org/overview/][ELK stack]] allows us to process, aggregate, store,
  search, and analyze logs with a lot of metadata from Windows and
  Linux computers.
  - Elasticsearch is based on Apache Lucene and is a very fast,
    distributed real-time search and analytics engine that offers a rich
    query DSL via a REST API
  - Logstash converts logs to JSON according to your rules and ships
    them to Elasticsearch
  - Kibana is a real-time visualization engine for Elastic- search

  We also use the [[http://beaver.readthedocs.org/][Beaver Python daemon]] to ship logs to Logstash from
  the Linux Lab computers.

  Elasticsearch also allows us to modify log entries after the fact,
  so we are going to insert demographic and role data to augment the
  username field. This data will include things like class standing
  (Freshman, Sophomore, etc.), department, course enrollment, and
  affiliation (Alumni, Student, Staff, etc.).

* Our ELK Environment

  The ELK Environment at CAEN consists of a two-node Elasticsearch
  cluster, a log aggregation server to collect the logs from Beaver,
  and a Kibana web server to present some of the data.

  The College of Engineering computer labs have about 1000 computers,
  each of which dual-boots into either Linux or Windows.  When they
  are running Linux, they use the Beaver Python daemon to deliver
  their software usage information to an aggregation server that does
  some processing and delivers the logs on to the Elasticsearch
  cluster.  When the computers are running Windows, about a dozen of
  them log their software usage.  This is a test before we deploy the
  logging agents to the rest of the Windows computers.

  The HPC Cluster comprises about 1500 computers, all of which run
  Logstash as a daemon and deliver their logs via Redis to the
  Elasticsearch cluster.

  The configuration of each of these is different.  The Linux
  computers in the computer labs use [[file:linux-lab-beaver.org][Beaver and its configuration]] to
  gather and ship software usage information from the ~auditd~ logs.
  The Linux computers that make up the HPC cluster use [[file:linux-hpc-logstash.org][Logstash and
  its configuration]] to gather and ship software usage information from
  their ~auditd~ logs.  The Windows computers in the computer labs use
  the /Audit Process Creation on Success/ and /Audit Process
  Termination on Success/ settings in the Group Policy to log those
  events via the Windows Event log, where Logstash picks up those
  entries using [[file:windows-lab-logstash.org][a Windows-specific Logstash configuration file]].

* Results

  Once the data is in Elasticsearch, it is replicated between our two
  nodes and is available for searching.

  Kibana is the web-based front-end that is part of the ELK
  stack.[fn:1] Some examples of representing software usage data and
  other data in Kibana are [[file:kibana-examples.org][here]].

  You can also query Elasticsearch directly, using either a URL query
  string, or a JSON-structured ~GET~ query.  Version 3 of Kibana
  doesn't support aggregating data (this is similar to SQL ~JOIN~
  statements), where as the JSON-structured queries do.  Additionally,
  having data reported via a Python script can sometimes be more
  useful than data reported via a web page.  Some examples of direct
  queries are [[file:elasticsearch-queries.org][here]].

* Local Dictionary 						   :noexport:
#  LocalWords:  Elasticsearch Logstash username Lucene Kibana Redis
#  LocalWords:  analytics DSL API

* Footnotes

[fn:1]   Other analysis and presentation engines can also be used with
Logstash data.  We also use Graphite to ingest data from Logstash from
our Luster Object Storage Servers, skipping Elasticsearch altogether.
